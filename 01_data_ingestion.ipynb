{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4616de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70dfd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Billing File\n",
    "file_path = (\n",
    "    r\"C:\\Users\\pirat\\Dropbox\\Consulting Inc\\Upperline Health\\1. Payor Data & Contracts\"\n",
    "    r\"\\99-Athena Reports\\ULH All Payors FL - DOS 2024 & YTD June 2025 - as of 11.17.25.xlsx\"\n",
    ")\n",
    "\n",
    "# Read all sheets (dict: {sheet_name: DataFrame})\n",
    "sheets_dict = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# If the file really only has those 2 relevant sheets, this will grab both\n",
    "df_raw = pd.concat(sheets_dict.values(), ignore_index=True)\n",
    "\n",
    "# delete duplicate rows\n",
    "df_raw = df_raw.drop_duplicates(keep='first')\n",
    "\n",
    "# BENCHMARK: 1m per 1 mil rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8833863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial cleaning\n",
    "df_clean = df_raw.copy()\n",
    "\n",
    "# change net payment from negative to positive\n",
    "df_clean['Net Payment'] = df_clean['Net Payment'].abs()\n",
    "\n",
    "# create avg paid per claim\n",
    "df_clean['Avg_Paid_Per_Claim'] = (df_clean['Net Payment']/df_clean['Charge Units']).fillna(0)\n",
    "\n",
    "# create key from Claim ID and Patient ID\n",
    "df_clean[\"Patient_Claim_Key\"] = (\n",
    "    df_clean[\"Claim ID\"].astype(str)\n",
    "    + \"-\"\n",
    "    + df_clean[\"Patient ID\"].astype(str)\n",
    "    + \"-\"\n",
    "    + df_clean[\"Date of Service\"].astype(str)\n",
    ")\n",
    "\n",
    "# Get \"State\" from first two characters of [\"Service Department\"]\n",
    "df_clean[\"State\"] = df_clean[\"Service Department\"].str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93170fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Payer Crosswalk File\n",
    "file_path = (\n",
    "    r\"C:\\Users\\pirat\\Dropbox\\Consulting Inc\\Upperline Health\\1. Payor Data & Contracts\\99-Athena Reports\"\n",
    "    r\"\\Payor Mapping_FIN.xlsx\"\n",
    ")\n",
    "\n",
    "# Read only \"Payor Mapping_FIN\" sheet\n",
    "df_payor_mapping = pd.read_excel(file_path, sheet_name=\"PayorMap_FIN\")\n",
    "\n",
    "df_payor_mapping[\"INSNAME_OPS_key\"] = (\n",
    "    df_payor_mapping[\"INSNAME_OPS\"].str.upper().str.strip()\n",
    ")\n",
    "\n",
    "# drop unused columns\n",
    "df_payor_mapping = df_payor_mapping[[\n",
    "    \"INSNAME_OPS_key\",\n",
    "    \"INSNAME_OPS\",\n",
    "    \"PAYORCAT_FIN\",\n",
    "    \"PARENTCO_NAME_FIN\"\n",
    "]]\n",
    "\n",
    "# delete duplicate rows\n",
    "df_payor_mapping = df_payor_mapping.drop_duplicates(\"INSNAME_OPS_key\", keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2033c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize keys to uppercase, stripped\n",
    "df_clean[\"Primary Insurance_key\"] = (\n",
    "    df_clean[\"Primary Insurance\"].str.upper().str.strip()\n",
    ")\n",
    "\n",
    "# Merge on the normalized keys\n",
    "df_merged = pd.merge(\n",
    "    df_clean,\n",
    "    df_payor_mapping[[\"INSNAME_OPS_key\", \"INSNAME_OPS\", \"PAYORCAT_FIN\", \"PARENTCO_NAME_FIN\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"Primary Insurance_key\",\n",
    "    right_on=\"INSNAME_OPS_key\",\n",
    ")\n",
    "\n",
    "# drop helper columns\n",
    "df_merged = df_merged.drop(columns=[\"Primary Insurance_key\", \"INSNAME_OPS_key\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca4ddca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# base this on the raw insurance name\n",
    "ins = df_merged[\"INSNAME_OPS\"].fillna(\"\").str.lower()\n",
    "\n",
    "# build a guess for every row\n",
    "payor_guess = np.select(\n",
    "    [\n",
    "        ins.str.contains(\"medicare\") | ins.str.contains(\"mcr\"),\n",
    "        ins.str.contains(\"medicaid\") | ins.str.contains(\"mcd\"),\n",
    "        ins.str.contains(\"tricare\") | ins.str.contains(\"exchange\"),\n",
    "    ],\n",
    "    [\"MEDICARE\", \"MEDICAID\", \"OTHER\"],\n",
    "    default=\"COMMERCIAL\",\n",
    ")\n",
    "\n",
    "# use it only where PAYORCAT_FIN is null\n",
    "df_merged[\"PAYORCAT_FIN\"] = df_merged[\"PAYORCAT_FIN\"].fillna(\n",
    "    pd.Series(payor_guess, index=df_merged.index)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
