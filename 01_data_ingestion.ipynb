{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4616de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f316d",
   "metadata": {},
   "source": [
    "### Import Billing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70dfd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Billing File\n",
    "file_path = (\n",
    "    r\"C:\\Users\\pirat\\Dropbox\\Consulting Inc\\Upperline Health\\1. Payor Data & Contracts\"\n",
    "    r\"\\99-Athena Reports\\ULH All Payors FL - DOS 2024 & YTD June 2025 - as of 11.17.25.xlsx\"\n",
    ")\n",
    "\n",
    "# Read all sheets (dict: {sheet_name: DataFrame})\n",
    "sheets_dict = pd.read_excel(file_path, sheet_name=None)\n",
    "\n",
    "# If the file really only has those 2 relevant sheets, this will grab both\n",
    "df_raw = pd.concat(sheets_dict.values(), ignore_index=True)\n",
    "\n",
    "# delete duplicate rows\n",
    "df_raw = df_raw.drop_duplicates(keep='first')\n",
    "\n",
    "# BENCHMARK: 1m per 1 mil rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8833863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial cleaning\n",
    "df_clean = df_raw.copy()\n",
    "\n",
    "# change net payment from negative to positive\n",
    "df_clean['Net Payment'] = df_clean['Net Payment'].abs()\n",
    "\n",
    "# create avg paid per claim\n",
    "df_clean['Avg_Paid_Per_Claim'] = (df_clean['Net Payment']/df_clean['Charge Units']).fillna(0)\n",
    "\n",
    "# create key from Claim ID and Patient ID\n",
    "df_clean[\"Patient_Claim_Key\"] = (\n",
    "    df_clean[\"Claim ID\"].astype(str)\n",
    "    + \"-\"\n",
    "    + df_clean[\"Patient ID\"].astype(str)\n",
    "    + \"-\"\n",
    "    + df_clean[\"Date of Service\"].astype(str)\n",
    ")\n",
    "\n",
    "# Get \"State\" from first two characters of [\"Service Department\"]\n",
    "df_clean[\"State\"] = df_clean[\"Service Department\"].str[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb998a8",
   "metadata": {},
   "source": [
    "### Import Payor Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93170fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Payer Crosswalk File\n",
    "file_path = (\n",
    "    r\"C:\\Users\\pirat\\Dropbox\\Consulting Inc\\Upperline Health\\1. Payor Data & Contracts\\99-Athena Reports\"\n",
    "    r\"\\Payor Mapping_FIN.xlsx\"\n",
    ")\n",
    "\n",
    "# Read only \"Payor Mapping_FIN\" sheet\n",
    "df_payor_mapping = pd.read_excel(file_path, sheet_name=\"PayorMap_FIN\")\n",
    "\n",
    "df_payor_mapping[\"INSNAME_OPS_key\"] = (\n",
    "    df_payor_mapping[\"INSNAME_OPS\"].str.upper().str.strip()\n",
    ")\n",
    "\n",
    "# drop unused columns\n",
    "df_payor_mapping = df_payor_mapping[[\n",
    "    \"INSNAME_OPS_key\",\n",
    "    \"INSNAME_OPS\",\n",
    "    \"PAYORCAT_FIN\",\n",
    "    \"PARENTCO_NAME_FIN\"\n",
    "]]\n",
    "\n",
    "# delete duplicate rows\n",
    "df_payor_mapping = df_payor_mapping.drop_duplicates(\"INSNAME_OPS_key\", keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed632fc",
   "metadata": {},
   "source": [
    "### Merge Payor Map to Billing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2033c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize keys to uppercase, stripped\n",
    "df_clean[\"Primary Insurance_key\"] = (\n",
    "    df_clean[\"Primary Insurance\"].str.upper().str.strip()\n",
    ")\n",
    "\n",
    "# Merge on the normalized keys\n",
    "df_merged = pd.merge(\n",
    "    df_clean,\n",
    "    df_payor_mapping[[\"INSNAME_OPS_key\", \"INSNAME_OPS\", \"PAYORCAT_FIN\", \"PARENTCO_NAME_FIN\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"Primary Insurance_key\",\n",
    "    right_on=\"INSNAME_OPS_key\",\n",
    ")\n",
    "\n",
    "# drop helper columns\n",
    "df_merged = df_merged.drop(columns=[\"Primary Insurance_key\", \"INSNAME_OPS_key\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a4f20e",
   "metadata": {},
   "source": [
    "### Additional Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca4ddca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling in PAYORCAT_FIN. \n",
    "# First make a series based on the raw insurance name\n",
    "ins = df_merged[\"INSNAME_OPS\"].fillna(\"\").str.lower()\n",
    "\n",
    "# build a guess for every row\n",
    "payor_guess = np.select(\n",
    "    [\n",
    "        ins.str.contains(\"medicare\") | ins.str.contains(\"mcr\"),\n",
    "        ins.str.contains(\"medicaid\") | ins.str.contains(\"mcd\"),\n",
    "        ins.str.contains(\"tricare\") | ins.str.contains(\"exchange\"),\n",
    "    ],\n",
    "    [\"MEDICARE\", \"MEDICAID\", \"OTHER\"],\n",
    "    default=\"COMMERCIAL\",\n",
    ")\n",
    "\n",
    "# use it only where PAYORCAT_FIN is null\n",
    "df_merged[\"PAYORCAT_FIN\"] = df_merged[\"PAYORCAT_FIN\"].fillna(\n",
    "    pd.Series(payor_guess, index=df_merged.index)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dfe5d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete any rows where \"Date of Service\" is before 2024-01-01\n",
    "df_merged = df_merged[\n",
    "    pd.to_datetime(df_merged[\"Date of Service\"]) >= pd.to_datetime(\"2024-01-01\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc660794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parts = (\n",
    "    df_merged[\"Procedure Code\"]\n",
    "      .fillna(\"\")\n",
    "      .astype(str)\n",
    "      .str.split(\",\", expand=True)\n",
    "      .apply(lambda s: s.str.strip())\n",
    "      .replace(\"\", pd.NA)\n",
    ")\n",
    "\n",
    "# rename: first col = CPT_Code_Core, remaining = Mod1, Mod2, ...\n",
    "parts.columns = [\"CPT_Code_Core\"] + [f\"Mod{i}\" for i in range(1, parts.shape[1])]\n",
    "\n",
    "df_merged = df_merged.join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6ce8ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of price-altering modifiers\n",
    "PRICE_ALTERING_MODS = {\n",
    "    \"26\",\"TC\",\n",
    "    # \"50\",\"51\",\n",
    "    # \"52\",\"53\",\n",
    "    # \"54\",\"55\",\"56\",\n",
    "    # \"62\",\"66\",\n",
    "    # \"80\",\"81\",\"82\",\"AS\",\n",
    "    # \"LT\",\"RT\",  # uncomment if you want laterality treated as price-altering\n",
    "}\n",
    "\n",
    "mod_cols = [c for c in df_merged.columns if c.startswith(\"Mod\")]\n",
    "\n",
    "# Normalize modifier cells (strip, uppercase, handle blanks)\n",
    "mods = (\n",
    "    df_merged[mod_cols]\n",
    "      .astype(\"string\")\n",
    "      .apply(lambda s: s.str.strip().str.upper())\n",
    "      .replace({\"\": pd.NA, \"NAN\": pd.NA, \"NONE\": pd.NA})\n",
    ")\n",
    "\n",
    "# First matching price-altering modifier, left-to-right (Mod1, Mod2, ...)\n",
    "df_merged[\"Price_Modifier\"] = (\n",
    "    mods.where(mods.isin(PRICE_ALTERING_MODS))\n",
    "        .bfill(axis=1)\n",
    "        .iloc[:, 0]\n",
    ")\n",
    "\n",
    "df_merged[\"Has_Price_Modifier\"] = df_merged[\"Price_Modifier\"].notna()\n",
    "\n",
    "# Build Code_Final = CPT_Code_Core + \"-\" + first price-altering modifier (if any)\n",
    "core = df_merged[\"CPT_Code_Core\"].astype(\"string\").str.strip()\n",
    "\n",
    "df_merged[\"Code_Final\"] = core.where(\n",
    "    df_merged[\"Price_Modifier\"].isna(),\n",
    "    core + \"-\" + df_merged[\"Price_Modifier\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b252f523",
   "metadata": {},
   "source": [
    "### Import Service Category Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e87711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import service category mapping\n",
    "file_path = (\n",
    "    r\"C:\\Users\\pirat\\Dropbox\\Consulting Inc\\Upperline Health\\1. Payor Data & Contracts\\Service Code List - Upperline.xlsx\"\n",
    ")\n",
    "\n",
    "df_svc_cat = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5af8e95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge service category mapping\n",
    "df_tested = df_merged.copy()\n",
    "df_tested = pd.merge(\n",
    "    df_tested,\n",
    "    df_svc_cat[[\"Code Full\", \"Category Name\", \"Sub-Category Name\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"Code_Final\",\n",
    "    right_on=\"Code Full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3370967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to Excel\n",
    "output_path = (\n",
    "    r\"C:\\Users\\pirat\\Dropbox\\Consulting Inc\\Upperline Health\\1. Payor Data & Contracts\\99-Athena Reports\"\n",
    "    r\"\\ULH_Billing_Processed.xlsx\"\n",
    ")\n",
    "\n",
    "df_tested.to_excel(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
